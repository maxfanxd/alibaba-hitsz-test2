`torch_dtype` is deprecated! Use `dtype` instead!
使用设备: cuda
嵌入设备: cuda
加载候选药物 651 种
加载模型...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:11,  5.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.78s/it]
Traceback (most recent call last):
  File "/workspace/alibaba-hitsz-test2/infer_lora_qwen.py", line 385, in <module>
    main()
  File "/workspace/alibaba-hitsz-test2/infer_lora_qwen.py", line 285, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 750, in _load_state_dict_into_meta_model
    param = param.to(casting_dtype)
KeyboardInterrupt
